hadoop-slave1:
   image: tonywell/docker-hbase
   container_name: hadoop-slave1
   volumes:
     - ./docker-hadoop/conf:/usr/local/hadoop/etc/hadoop
     - ./docker-hive/conf:/usr/local/hive/conf
     - ./docker-spark/conf:/usr/local/spark/conf
     - ./docker-hbase/conf:/usr/local/hbase/conf
   net: zoo
hadoop-slave2:
   image: tonywell/docker-hbase
   container_name: hadoop-slave2
   volumes:
     - ./docker-hadoop/conf:/usr/local/hadoop/etc/hadoop
     - ./docker-hive/conf:/usr/local/hive/conf
     - ./docker-spark/conf:/usr/local/spark/conf
     - ./docker-hbase/conf:/usr/local/hbase/conf
   net: zoo
hadoop-slave3:
   image: tonywell/docker-hbase
   container_name: hadoop-slave3
   volumes:
     - ./docker-hadoop/conf:/usr/local/hadoop/etc/hadoop
     - ./docker-hive/conf:/usr/local/hive/conf
     - ./docker-spark/conf:/usr/local/spark/conf
     - ./docker-hbase/conf:/usr/local/hbase/conf
   net: zoo
hadoop-master:
   image: tonywell/docker-hbase
   container_name: hadoop-master
   volumes:
     - ./docker-hadoop/conf:/usr/local/hadoop/etc/hadoop
     - ./docker-hive/conf:/usr/local/hive/conf
     - ./docker-spark/conf:/usr/local/spark/conf
     - ./docker-hbase/conf:/usr/local/hbase/conf
   net: zoo
   #command: bash /usr/local/hadoop/bin/hdfs namenode -format -y && sh /usr/local/hadoop/sbin/start-all.sh -yes && sh /usr/local/spark/sbin/start-all.sh && sh /usr/local/hbase/bin/start-hbase.sh && ping localhost > /dev/null
   ports:
     - "50070:50070"
     - "9083:9083"
     - "8088:8088"
     - "8080:8080"
     - "8042:8042"
     - "16010:16010"
   links:
     - hadoop-slave1
     - hadoop-slave2
     - hadoop-slave3
